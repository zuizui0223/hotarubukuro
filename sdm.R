
# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
library(terra)
library(sf)
library(rnaturalearth)

dir.create("data/raw", TRUE, TRUE)
dir.create("data/clean", TRUE, TRUE)

# 1) ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
url  <- "https://data.worldpop.org/GIS/Population_Density/Global_2000_2020_1km/2020/JPN/jpn_pd_2020_1km.tif"
fraw <- "data/raw/worldpop_jpn_pd_2020_1km.tif"
if(!file.exists(fraw)) download.file(url, fraw, mode="wb")

# 2) æ—¥æœ¬ãƒãƒªã‚´ãƒ³ã¨1 kmãƒ†ãƒ³ãƒ—ãƒ¬
jpn  <- rnaturalearth::ne_countries(country="japan", scale="medium", returnclass="sf")
tmpl <- rast(ext(vect(jpn)), resolution=0.008333, crs="EPSG:4326")  # â‰ˆ1 km

# 3) èª­ã¿è¾¼ã¿ãƒ»ã‚¯ãƒªãƒƒãƒ—ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬ã¸çµ±ä¸€
wp  <- rast(fraw)                             # å˜ä½: äºº/kmÂ²
wp  <- crop(wp, vect(jpn), snap="out")        # å¿µã®ãŸã‚æ—¥æœ¬ç¯„å›²ã«åˆ‡ã‚Šå‡ºã—
wp1 <- project(wp, crs(tmpl), method="bilinear") |> resample(tmpl, "bilinear")

# 4) ä¿å­˜
writeRaster(wp1, "data/clean/worldpop_jpn_pd_2020_1km.tif", overwrite=TRUE)


# å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
pkgs <- c("rgbif","sf","rnaturalearth","dplyr","readr")
new  <- pkgs[!pkgs %in% installed.packages()[,1]]; if(length(new)) install.packages(new)
invisible(lapply(pkgs, library, character.only=TRUE))

dir.create("data/gbif", recursive=TRUE, showWarnings=FALSE)

# ã™ã§ã«å–å¾—æ¸ˆã¿ï¼š
bombus_key <- 1340278

# 1) ã€ŒåŒ—æµ·é“ä»¥å¤–ã€ã®ãƒãƒªã‚´ãƒ³ã‚’ä½œæˆ
jp_admin1 <- rnaturalearth::ne_states(country="japan", returnclass="sf")

# éƒ½é“åºœçœŒåã®åˆ—ã‚’æ¨å®šï¼ˆç’°å¢ƒã”ã¨ã«åˆ—åãŒé•ã†å¯¾ç­–ï¼‰
nmcol <- intersect(c("name","name_en","nameascii","name_ja","name_en"), names(jp_admin1))[1]
stopifnot(!is.na(nmcol))

# åŒ—æµ·é“ä»¥å¤–ã‚’æŠ½å‡º â†’ 1ã¤ã®ãƒãƒªã‚´ãƒ³ã« union
poly_no_hkd <- jp_admin1 |>
  dplyr::filter(.data[[nmcol]] != "Hokkaido") |>
  st_make_valid() |>
  st_union() |>
  st_make_valid()

# è»½é‡åŒ–ï¼ˆä»»æ„ï¼‰
poly_no_hkd <- st_simplify(poly_no_hkd, dTolerance=0.001)
wkt <- st_as_text(poly_no_hkd)

Sys.setenv(
  GBIF_USER  = "zuizui",
  GBIF_PWD   = "rich761327",
  GBIF_EMAIL = "rachelzhang0223@gmail.com"
)

u<-Sys.getenv("GBIF_USER"); p<-Sys.getenv("GBIF_PWD"); e<-Sys.getenv("GBIF_EMAIL")
# 1) predicate ã‚’ä½œæˆ
preds <- list(
  rgbif::pred("taxonKey", bombus_key),
  rgbif::pred("hasCoordinate", TRUE),
  rgbif::pred_not(rgbif::pred("hasGeospatialIssue", TRUE)),
  rgbif::pred_within(wkt),          # â† geometryã¯ pred_within ãŒç¢ºå®Ÿ
  rgbif::pred("country", "JP")
  # ä¾‹: rgbif::pred_gte("year", 2000),
  #     rgbif::pred_lte("coordinateUncertaintyInMeters", 1000)
)

# 2) do.call ã§å€‹ã€…ã® predicate ã‚’å±•é–‹ã—ã¦æ¸¡ã™
key <- do.call(
  rgbif::occ_download,
  c(preds, list(format = "SIMPLE_CSV", user = u, pwd = p, email = e))
)
cat("GBIF download key:", key, "\n")
library(rgbif); library(sf); library(readr); library(dplyr)

dir.create("data/gbif", recursive=TRUE, showWarnings=FALSE)

# 1) å®Œäº†å¾…ã¡
rgbif::occ_download_wait("0001808-251025141854904")

# 2) ZIPå–å¾— & å±•é–‹ã›ãšã«èª­ã¿è¾¼ã¿
zipf <- rgbif::occ_download_get("0001808-251025141854904",
                                path="data/gbif", overwrite=TRUE)
occ  <- rgbif::occ_download_import(zipf)  # data.frame

# 3) ã€ŒåŒ—æµ·é“ä»¥å¤–ã€ã®ä¿é™ºã‚¯ãƒªãƒƒãƒ—ï¼ˆwkt ã¯å‰ã«ä½œã£ãŸ poly_no_hkd ã®WKTã‚’å†åˆ©ç”¨ï¼‰
#    ã‚‚ã—ç’°å¢ƒãŒæ–°è¦ãªã‚‰ poly_no_hkd ã‚’å†ä½œæˆã—ã¦ãã ã•ã„
# ptsåŒ– â†’ ãƒãƒªã‚´ãƒ³ã«å«ã¾ã‚Œã‚‹ç‚¹ã ã‘æŠ½å‡º
pts <- st_as_sf(occ, coords=c("decimalLongitude","decimalLatitude"),
                crs=4326, remove=FALSE)
inside <- st_intersects(pts, poly_no_hkd, sparse=FALSE)[,1]
occ_out <- occ[inside, ]

# 4) ï¼ˆä»»æ„ï¼‰ã¡ã‚‡ã„æ•´å½¢ï¼šé‡è¤‡ã‚„æ˜ã‚‰ã‹ãªå¤‰ãªç‚¹ã®é™¤å»ä¾‹
#    åŒä¸€ç‚¹é‡è¤‡ã‚’è½ã¨ã™ï¼ˆgbifID ã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯ã ãŒå¿µã®ãŸã‚ï¼‰
occ_out <- occ_out |>
  distinct(decimalLongitude, decimalLatitude, eventDate, .keep_all=TRUE)

# 5) ä¿å­˜ï¼ˆCSV ã¨åœ°ç†ä»˜ãGPKGï¼‰
keep <- intersect(c("gbifID","scientificName","species",
                    "decimalLatitude","decimalLongitude",
                    "eventDate","year","basisOfRecord",
                    "occurrenceStatus","datasetKey",
                    "institutionCode","collectionCode","countryCode","locality"),
                  names(occ_out))
readr::write_csv(occ_out[, keep],
                 "data/gbif/gbif_bombus_JP_noHokkaido.csv")

pts_out <- st_as_sf(occ_out[, keep],
                    coords=c("decimalLongitude","decimalLatitude"),
                    crs=4326, remove=FALSE)
st_write(pts_out, "data/gbif/gbif_bombus_JP_noHokkaido.gpkg", delete_dsn=TRUE)

cat("âœ… ä¿å­˜:\n - data/gbif/gbif_bombus_JP_noHokkaido.csv\n - data/gbif/gbif_bombus_JP_noHokkaido.gpkg\n")



library(dplyr); library(readr); library(stringr); library(sf)

csv_path <- "data/gbif/gbif_bombus_JP_noHokkaido.csv"
occ <- readr::read_csv(csv_path, show_col_types = FALSE)

# ç¨®åæ•´å‚™
occ$species_fixed <- if("species" %in% names(occ) && any(!is.na(occ$species))){
  occ$species
} else if("scientificName" %in% names(occ)){
  stringr::str_trim(stringr::str_extract(occ$scientificName, "^[A-Za-z]+\\s+[A-Za-z\\-]+"))
} else {
  NA_character_
}
occ <- occ %>% filter(!is.na(species_fixed), species_fixed != "")

# ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€
dir.create("data/gbif/species_filtered", recursive = TRUE, showWarnings = FALSE)

############################################################
# åœ¨æ¥ã®ãƒãƒ«ãƒãƒŠãƒãƒã ã‘ã‚’ä¿å­˜ï¼ˆ>=20ä»¶ã¯ä»»æ„ã§åˆ‡æ›¿å¯ï¼‰
############################################################

library(dplyr); library(readr); library(stringr); library(sf)

# å…ƒCSVï¼ˆåŒ—æµ·é“ä»¥å¤–ã§DLã—ãŸã‚„ã¤ï¼‰
csv_path <- "data/gbif/gbif_bombus_JP_noHokkaido.csv"
occ <- readr::read_csv(csv_path, show_col_types = FALSE)

# ç¨®åæ•´å‚™ï¼ˆspeciesãŒç©ºãªã‚‰ scientificName ã‹ã‚‰å±+ç¨®ã‚’æŠ½å‡ºï¼‰
occ$species_fixed <- if("species" %in% names(occ) && any(!is.na(occ$species))){
  occ$species
} else if("scientificName" %in% names(occ)){
  stringr::str_trim(stringr::str_extract(occ$scientificName, "^[A-Za-z]+\\s+[A-Za-z\\-]+"))
} else NA_character_

occ <- occ %>% filter(!is.na(species_fixed), species_fixed != "")

# åœ¨æ¥12ç¨®ï¼ˆå¤–æ¥: B. terrestris ã¯é™¤å¤–ï¼‰
native_species <- c(
  "Bombus ardens",
  "Bombus beaticola",
  "Bombus consobrinus",
  "Bombus deuteronymus",
  "Bombus diversus",
  "Bombus honshuensis",
  "Bombus hypnorum",
  "Bombus hypocrita",
  "Bombus ignitus",
  "Bombus pseudobaicalensis",
  "Bombus schrencki",
  "Bombus ussurensis"
)

native_occ <- occ %>% filter(species_fixed %in% native_species)

# ï¼ˆä»»æ„ï¼‰20ä»¶ä»¥ä¸Šã ã‘ã«é™å®šã—ãŸã„å ´åˆã¯ä¸‹ã®1è¡Œã‚’æœ‰åŠ¹åŒ–
# native_occ <- native_occ %>% group_by(species_fixed) %>% filter(n() >= 20) %>% ungroup()

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
dir.create("data/gbif/species_native", recursive = TRUE, showWarnings = FALSE)

# ç¨®ã”ã¨ã«æ›¸ãå‡ºã—
native_list <- split(native_occ, native_occ$species_fixed)

for(sp in names(native_list)){
  df <- native_list[[sp]]
  fname_base <- stringr::str_replace_all(sp, "[^A-Za-z0-9]+", "_")
  csv_file <- file.path("data/gbif/species_native", paste0(fname_base, ".csv"))
  readr::write_csv(df, csv_file)
  
  # GPKGã‚‚ä¿å­˜ï¼ˆåº§æ¨™ãŒã‚ã‚Œã°ï¼‰
  if(all(c("decimalLongitude","decimalLatitude") %in% names(df))){
    sfobj <- st_as_sf(df, coords = c("decimalLongitude","decimalLatitude"),
                      crs = 4326, remove = FALSE)
    gpkg_file <- file.path("data/gbif/species_native", paste0(fname_base, ".gpkg"))
    st_write(sfobj, gpkg_file, delete_dsn = TRUE, quiet = TRUE)
  }
  cat("âœ…", sp, ":", nrow(df), "records â†’", csv_file, "\n")
}

# ã¾ã¨ã‚ï¼ˆåœ¨æ¥ç¨®ã®ä»¶æ•°è¡¨ï¼‰
counts <- native_occ %>% count(species_fixed, sort = TRUE)
readr::write_csv(counts, "data/gbif/species_native/_counts_native.csv")

cat("ğŸ‰ å®Œäº†: data/gbif/species_native/ ã«åœ¨æ¥ç¨®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚\n")





suppressPackageStartupMessages({
  library(terra)
  library(sf)
  library(dplyr)
  library(usdm)
  library(tools)
  library(rnaturalearth)
  library(rnaturalearthdata)
  library(ENMeval)   # v2.0.5.2
})

set.seed(42)



env_dir <- "~/Desktop/beeenv"              # ç’°å¢ƒTIFãƒ•ã‚©ãƒ«ãƒ€
occ_dir <- "data/gbif/species_native"      # åœ¨æ¥ç¨®ã‚ªã‚«ãƒ¬ãƒ³ã‚¹CSVãƒ•ã‚©ãƒ«ãƒ€
out_dir <- "data/clean"
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
dir.create(file.path(out_dir, "stack"), recursive = TRUE, showWarnings = FALSE)


env_files <- list.files(env_dir, pattern = "\\.tif$", full.names = TRUE)
stopifnot("ç’°å¢ƒTIFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" = length(env_files) > 0)

is_wc <- grepl("worldcover", basename(env_files), ignore.case = TRUE)
wc_files   <- env_files[is_wc]
cont_files <- env_files[!is_wc]
if (length(wc_files) != 1) message("âš ï¸ WorldCover ãŒ1æšã§ãªã„å ´åˆã¯ is_wc ã®æ¡ä»¶ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")


occ_csvs <- list.files(occ_dir, pattern = "\\.csv$", full.names = TRUE)
stopifnot("åœ¨æ¥ç¨®CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" = length(occ_csvs) > 0)
occ_all  <- bind_rows(lapply(occ_csvs, read.csv))
occ_all  <- occ_all %>% distinct(decimalLongitude, decimalLatitude, .keep_all = TRUE)
occ_pts  <- vect(occ_all, geom = c("decimalLongitude","decimalLatitude"), crs = "EPSG:4326")
cat("âœ… ã‚ªã‚«ãƒ¬ãƒ³ã‚¹æ•°:", nrow(occ_all), "\n")


tmpl_path <- if (length(cont_files) >= 1) cont_files[1] else wc_files[1]
tmpl  <- rast(tmpl_path)
crs_t <- crs(tmpl); res_t <- res(tmpl)


to_tmpl_extent <- function(f, mthd = "bilinear"){
  r <- rast(f)
  if (!isTRUE(all.equal(crs(r), crs_t))) r <- project(r, crs_t, method = mthd)
  if (!isTRUE(all.equal(res(r), res_t))) r <- resample(r, tmpl, method = mthd)
  ext(r)
}
ext_list <- c(
  lapply(cont_files, to_tmpl_extent, mthd = "bilinear"),
  lapply(wc_files,   to_tmpl_extent, mthd = "near")
)
common_ext <- Reduce(intersect, ext_list)


grid <- crop(extend(tmpl, common_ext), common_ext)


align_one <- function(f, mthd){
  r <- rast(f)
  if (!isTRUE(all.equal(crs(r), crs_t))) r <- project(r, crs_t, method = mthd)
  r <- resample(r, grid, method = mthd)  
  r
}
cont_aligned <- if (length(cont_files)) rast(lapply(cont_files, align_one, mthd = "bilinear")) else NULL
wc_aligned   <- if (length(wc_files))   rast(lapply(wc_files,   align_one, mthd = "near"))     else NULL

if (!is.null(cont_aligned)) names(cont_aligned) <- file_path_sans_ext(basename(cont_files))
if (!is.null(wc_aligned))   names(wc_aligned)   <- file_path_sans_ext(basename(wc_files))


if (!is.null(cont_aligned)) {
  vals <- terra::extract(cont_aligned, occ_pts, ID = FALSE) |> as.data.frame()
  vals <- vals[stats::complete.cases(vals), , drop = FALSE]
  stopifnot("æŠ½å‡ºå€¤ãŒç©ºã§ã™ï¼ˆåº§æ¨™ç³»ã‚„ç¯„å›²ã‚’ç¢ºèªï¼‰" = nrow(vals) > 0)
  
  vif_res   <- usdm::vifstep(vals, th = 10)   
  keep_vars <- as.character(vif_res@results$Variables)
  
  cont_kept <- if (length(keep_vars)) subset(cont_aligned, keep_vars) else NULL
  write.csv(vif_res@results, file.path(out_dir, "vif_results_continuous.csv"), row.names = FALSE)
  cat("ğŸ“ VIFé€šéï¼ˆé€£ç¶šï¼‰:", if(length(keep_vars)) paste(keep_vars, collapse = ", ") else "(ãªã—)", "\n")
} else {
  cont_kept <- NULL
  message("âš ï¸ é€£ç¶šå¤‰æ•°ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€VIF ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
}


final_stack <- c(if(!is.null(cont_kept)) cont_kept, if(!is.null(wc_aligned)) wc_aligned)
stopifnot("å‡ºåŠ›ãƒ¬ã‚¤ãƒ¤ãŒã‚ã‚Šã¾ã›ã‚“" = nlyr(final_stack) > 0)

out_stack <- file.path(out_dir, "stack", "env_stack_final.tif")
writeRaster(final_stack, out_stack, overwrite = TRUE)
cat("ğŸ’¾ ä¿å­˜:", out_stack, "\n")

cat("ğŸ“ ãƒ¬ã‚¤ãƒ¤æ•°:", nlyr(final_stack), " / è§£åƒåº¦:", paste(res(final_stack), collapse = " x "), "\n")
cat("ğŸ“ ç¯„å›²:", as.vector(ext(final_stack)), "\n")


library(terra)
library(sf)
library(dplyr)
library(rnaturalearth)

# ============================================================
# 1. åŒ—æµ·é“ãƒ»å—è¥¿è«¸å³¶ã‚’é™¤ã„ãŸã€Œæœ¬åœŸãƒãƒªã‚´ãƒ³ã€ã‚’ä½œæˆ
# ============================================================
cat("ğŸ—ºï¸ æœ¬åœŸãƒãƒªã‚´ãƒ³ã‚’ä½œæˆä¸­...\n")

# æ—¥æœ¬åœ°å›³ãƒ‡ãƒ¼ã‚¿ã®å–å¾— (é«˜è§£åƒåº¦)
jp_all <- ne_countries(country = "Japan", scale = 10, returnclass = "sf")

# ãƒãƒ©ãƒãƒ©ã®å³¶ã«åˆ†è§£ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
jp_parts <- st_cast(jp_all, "POLYGON")
jp_parts$area_m2 <- as.numeric(st_area(jp_parts))

jp_mainland_parts <- jp_parts %>%
  bind_cols(st_coordinates(st_centroid(.))) %>%
  rename(lon = X, lat = Y) %>%
  filter(
    # é¢ç©ãƒ•ã‚£ãƒ«ã‚¿: 200km^2ä»¥ä¸Š (æœ¬å·ãƒ»å››å›½ãƒ»ä¹å·ãƒ»ä½æ¸¡ãƒ»æ·¡è·¯ãƒ»å¯¾é¦¬ãªã©ä¸»è¦å³¶ã®ã¿)
    area_m2 > 200 * 1e6,
    
    # ç·¯åº¦ãƒ•ã‚£ãƒ«ã‚¿: åŒ—æµ·é“(ç´„41.5åº¦ä»¥åŒ—)ã¨å—è¥¿è«¸å³¶(30åº¦ä»¥å—)ã‚’é™¤å¤–
    lat < 41.5, 
    lat > 30.0   
  )

# çµåˆã—ã¦1ã¤ã®ãƒãƒªã‚´ãƒ³ã«ã™ã‚‹
jp_mainland <- st_union(jp_mainland_parts) %>% st_as_sf()
jp_mainland <- vect(jp_mainland) # terraå½¢å¼ã«å¤‰æ›

cat("âœ… ãƒãƒªã‚´ãƒ³ä½œæˆå®Œäº†: æœ¬å·ãƒ»å››å›½ãƒ»ä¹å·ãƒ»ä¸»è¦å±å³¶ã®ã¿ãŒå«ã¾ã‚Œã¾ã™ã€‚\n")


# ============================================================
# 2. ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚“ã§ãƒã‚¹ã‚¯å‡¦ç†ï¼ˆCrop & Maskï¼‰
# ============================================================
cat("ğŸ”„ ãƒ©ã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ã‚¯å‡¦ç†ã‚’é–‹å§‹...\n")

# ç¾åœ¨ã®ã‚¹ã‚¿ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿
# â€» ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¯ã”è‡ªèº«ã®ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„
input_tif <- "data/clean/stack/env_stack_final.tif" 
env <- rast(input_tif)

# 1) Crop: ãƒãƒªã‚´ãƒ³ã®ç¯„å›²ã‚®ãƒªã‚®ãƒªã¾ã§ç”»åƒã‚’åˆ‡ã‚Šå–ã‚‹ï¼ˆä½™ç™½ã‚’å‰Šé™¤ï¼‰
env_final <- crop(env, jp_mainland)

# 2) Mask: ãƒãƒªã‚´ãƒ³ã®å¤–å´ï¼ˆæµ·ã€åŒ—æµ·é“ã€æ²–ç¸„ï¼‰ã‚’NAã«ã™ã‚‹
env_final <- mask(env_final, jp_mainland)


# ============================================================
# 3. çµæœã®ç¢ºèªã¨ä¿å­˜
# ============================================================

# NAç‡ã®ç¢ºèªï¼ˆå…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã»ã¼åŒã˜å€¤ã«ãªã‚‹ã¯ãšã§ã™ï¼‰
na_rates <- global(env_final, "isNA")$isNA / ncell(env_final)
cat("\nğŸ“Š å‡¦ç†å¾Œã®NAç‡ç¢ºèª (å…¨ã¦æƒã£ã¦ã„ã‚Œã°OK):\n")
print(head(sort(na_rates, decreasing = TRUE)))


# ä¿å­˜
output_tif <- "data/clean/stack/env_stack_mainland_masked.tif"
writeRaster(env_final, output_tif, overwrite = TRUE)

cat("\nğŸ‰ å®Œäº†ã—ã¾ã—ãŸï¼\n")
cat("ğŸ’¾ ä¿å­˜å…ˆ:", output_tif, "\n")
cat("ã“ã‚Œã§å…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒã€ŒåŒ—æµ·é“ãƒ»æ²–ç¸„æŠœãã®æ—¥æœ¬æœ¬åœŸã€ã®å½¢ã«çµ±ä¸€ã•ã‚Œã¾ã—ãŸã€‚\n")



env <- rast(output_tif)

# Categoricalå¤‰æ•°ã®æŒ‡å®š
cat_idx <- grep("worldcover", names(env), ignore.case = TRUE)
if (length(cat_idx) == 0) {
  categoricals <- NULL
} else {
  categoricals <- names(env)[cat_idx]
  # æ˜ç¤ºçš„ã«factoråŒ–ï¼ˆé‡è¦ï¼‰
  for(cat_name in categoricals){
    env[[cat_name]] <- as.factor(env[[cat_name]])
  }
}

# èƒŒæ™¯ç‚¹ç”Ÿæˆ
bg_xy <- terra::spatSample(
  env,
  size   = 10000,
  method = "random",
  values = FALSE,
  xy     = TRUE,
  na.rm  = TRUE
) |> as.data.frame()
colnames(bg_xy) <- c("lon","lat")

# è§£æå¯¾è±¡ç¨®
targets <- c(
  "Bombus_beaticola",
  "Bombus_ardens",
  "Bombus_honshuensis",
  "Bombus_diversus",
  "Bombus_consobrinus"
)

dir.create(out_root, recursive = TRUE, showWarnings=FALSE)

# ---- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— ----
for (sp in targets) {
  message("\n==== Running ENMevaluate for ", sp, " ====")
  
  csv <- file.path(occ_dir, paste0(sp, ".csv"))
  if (!file.exists(csv)) { warning("CSV not found: ", csv); next }
  
  df <- read.csv(csv, check.names = FALSE)
  
  # åº§æ¨™åˆ—ã®è‡ªå‹•æ¤œå‡º
  nl <- tolower(names(df))
  li <- which(nl %in% c("longitude","lon","decimallongitude","x"))[1]
  ai <- which(nl %in% c("latitude","lat","decimallatitude","y"))[1]
  
  if(is.na(li) || is.na(ai)){ warning("åº§æ¨™åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ", sp); next }
  
  occ <- df[, c(li, ai)]
  names(occ) <- c("lon","lat")
  occ <- occ[complete.cases(occ),]
  
  # åŒä¸€ã‚»ãƒ«é™¤å»
  cid <- cellFromXY(env, occ)
  occ <- occ[!duplicated(cid) & !is.na(cid),]
  n_occ <- nrow(occ)
  
  # â˜…ãƒ‡ãƒãƒƒã‚°: æœ‰åŠ¹åœ°ç‚¹æ•°ã®ç¢ºèª
  message("  -> Effective occurrences (n_occ) for ", sp, ": ", n_occ)
  
  if (n_occ < 5) {
    message("  -> SKIP: Too few occurrences (< 5).")
    next
  }
  
  # ENMevaluateå®Ÿè¡Œ (tryCatchã§ã‚¨ãƒ©ãƒ¼å›é¿)
  e <- tryCatch(
    ENMevaluate(
      occs         = occ,
      envs         = env,
      bg           = bg_xy,
      algorithm    = "maxnet",
      partitions   = "block",
      tune.args    = list(fc=c("L","LQ","LQH"), rm=1:5),
      categoricals = categoricals,
      parallel     = TRUE,
      numCores     = 8  
    ),
    error = function(err){
      warning(sp, " -> ENMevaluate FAILED: ", conditionMessage(err))
      return(NULL)
    }
  )
  
  if (is.null(e)) next
  
  # çµæœä¿å­˜
  sp_dir <- file.path(out_root, sp)
  dir.create(sp_dir, showWarnings=FALSE, recursive=TRUE)
  
  write.csv(eval.results(e),
            file.path(sp_dir, paste0(sp, "_results.csv")),
            row.names=FALSE)
  
  # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ä¸Šä½çµæœã‚’è¡¨ç¤º
  message("--- Top results for ", sp, " ---")
  print(head(eval.results(e), 3))
  
  saveRDS(e, file.path(sp_dir, paste0(sp, "_enmeval.rds")))
  message("âœ” saved ENMevaluate for ", sp)
}


# ============================================================
# 3. Best Model Selection & Prediction
# ============================================================

# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«é¸æŠé–¢æ•°
select_best <- function(res){
  # 1) CBI æœ€å¤§
  if ("cbi.val.avg" %in% names(res) && any(is.finite(res$cbi.val.avg))) {
    max_cbi <- max(res$cbi.val.avg, na.rm = TRUE)
    cand <- which(res$cbi.val.avg == max_cbi)
    
    # 2) AUC æœ€å¤§ (ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯)
    if ("auc.val.avg" %in% names(res)) {
      auc_sub <- res$auc.val.avg[cand]
      if (any(is.finite(auc_sub))) {
        cand <- cand[which.max(auc_sub)]
      }
    }
    
    # 3) OR10 æœ€å° (ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯)
    if ("or.10p.val.avg" %in% names(res)) {
      or_sub <- res$or.10p.val.avg[cand]
      if (any(is.finite(or_sub))) {
        cand <- cand[which.min(or_sub)]
      }
    }
    return(cand[1])
  }
  
  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: AICcæœ€å°
  if ("AICc" %in% names(res) && any(is.finite(res$AICc))) {
    return(which.min(res$AICc))
  }
  
  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: AUCæœ€å¤§
  if ("auc.val.avg" %in% names(res) && any(is.finite(res$auc.val.avg))) {
    return(which.max(res$auc.val.avg))
  }
  
  return(1L)
}

# äºˆæ¸¬ç”¨ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
predict_maxnet_rast <- function(env_rast, model, categoricals=NULL){
  terra::predict(
    env_rast,
    model,
    fun = function(m, newdata, ...) {
      if (!is.null(categoricals)) {
        for (cn in categoricals) {
          if (cn %in% colnames(newdata)) {
            newdata[[cn]] <- factor(as.character(newdata[[cn]]))
          }
        }
      }
      as.numeric(predict(m, newdata = as.data.frame(newdata), type = "cloglog"))
    },
    na.rm = TRUE
  )
}

# äºˆæ¸¬ãƒ«ãƒ¼ãƒ—
for (sp in targets) {
  sp_dir <- file.path(out_root, sp)
  rds <- file.path(sp_dir, paste0(sp, "_enmeval.rds"))
  if (!file.exists(rds)) next
  
  e <- readRDS(rds)
  res <- eval.results(e)
  
  # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«é¸æŠ
  best_i <- select_best(res)
  model <- eval.models(e)[[best_i]]
  
  message("-> Predicting ", sp, " | best row = ", best_i,
          " | fc=", res$fc[best_i], ", rm=", res$rm[best_i])
  
  # äºˆæ¸¬ãƒãƒƒãƒ—ä½œæˆ
  pred <- predict_maxnet_rast(env, model, categoricals)
  out_tif <- file.path(sp_dir, sprintf("%s_best_cloglog.tif", sp))
  writeRaster(pred, out_tif, overwrite=TRUE)
  
  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
  write.csv(cbind(species=sp, res[best_i, , drop=FALSE]),
            file.path(sp_dir, sprintf("%s_best_meta.csv", sp)),
            row.names = FALSE)
  
  message("âœ” saved prediction for ", sp)
}

cat("\nğŸ‰ ALL DONE â€” Processing Complete!\n")